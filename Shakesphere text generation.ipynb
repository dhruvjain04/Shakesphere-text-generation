{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Activation,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=tf.keras.utils.get_file('shakespeare','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text=open(path,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "print(text[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115367"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=text.lower()\n",
    "text=''.join(c for c in text if not c.isdigit())\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=sorted(list(set(text)))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int={c:i for i,c in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char=np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_char[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text=np.array([char_to_int[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115367,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 20, 29, 30, 31,  1, 14, 20, 31, 20, 37, 16, 25,  9,  0, 13, 16,\n",
       "       17, 26, 29, 16,  1, 34, 16,  1, 27, 29, 26, 14, 16, 16, 15,  1, 12,\n",
       "       25, 36,  1, 17, 32, 29, 31, 19, 16, 29,  6,  1, 19, 16, 12, 29,  1,\n",
       "       24, 16,  1, 30, 27, 16, 12, 22,  8,  0,  0, 12, 23, 23,  9,  0, 30,\n",
       "       27, 16, 12, 22,  6,  1, 30, 27, 16, 12, 22,  8,  0,  0, 17, 20, 29,\n",
       "       30, 31,  1, 14, 20, 31, 20, 37, 16, 25,  9,  0, 36, 26, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first citizen:\\nbefore we proceed any further, hear me speak.\\n\\nall:\\nspeak, speak.\\n\\nfirst citizen:\\nyou'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11043\n"
     ]
    }
   ],
   "source": [
    "total_num_seq=len(text) // (seq_len+1)\n",
    "print(total_num_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset=tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "i\n",
      "t\n",
      "i\n",
      "z\n",
      "e\n",
      "n\n",
      ":\n",
      "\n",
      "\n",
      "b\n",
      "e\n",
      "f\n",
      "o\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "c\n",
      "e\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "f\n",
      "u\n",
      "r\n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      ",\n",
      " \n",
      "h\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "m\n",
      "e\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "a\n",
      "k\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "a\n",
      "l\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      "s\n",
      "p\n",
      "e\n",
      "a\n",
      "k\n",
      ",\n",
      " \n",
      "s\n",
      "p\n",
      "e\n",
      "a\n",
      "k\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "f\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "i\n",
      "t\n",
      "i\n",
      "z\n",
      "e\n",
      "n\n",
      ":\n",
      "\n",
      "\n",
      "y\n",
      "o\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "for item in char_dataset.take(100):\n",
    "    print(int_to_char[item.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=char_dataset.batch(batch_size=seq_len+1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_target(seq):\n",
    "    input_text=seq[:-1]\n",
    "    output_text=seq[1:]\n",
    "    return input_text,output_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=sequences.map(create_seq_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 20 29 30 31  1 14 20 31 20 37 16 25  9  0 13 16 17 26 29 16  1 34 16\n",
      "  1 27 29 26 14 16 16 15  1 12 25 36  1 17 32 29 31 19 16 29  6  1 19 16\n",
      " 12 29  1 24 16  1 30 27 16 12 22  8  0  0 12 23 23  9  0 30 27 16 12 22\n",
      "  6  1 30 27 16 12 22  8  0  0 17 20 29 30 31  1 14 20 31 20 37 16 25  9\n",
      "  0 36 26 32]\n",
      "\n",
      "\n",
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n",
      "[20 29 30 31  1 14 20 31 20 37 16 25  9  0 13 16 17 26 29 16  1 34 16  1\n",
      " 27 29 26 14 16 16 15  1 12 25 36  1 17 32 29 31 19 16 29  6  1 19 16 12\n",
      " 29  1 24 16  1 30 27 16 12 22  8  0  0 12 23 23  9  0 30 27 16 12 22  6\n",
      "  1 30 27 16 12 22  8  0  0 17 20 29 30 31  1 14 20 31 20 37 16 25  9  0\n",
      " 36 26 32  1]\n",
      "\n",
      "\n",
      "irst citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you \n"
     ]
    }
   ],
   "source": [
    "for input_txt,output_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(\"\\n\")\n",
    "    print(\"\".join(int_to_char[input_txt.numpy()]))\n",
    "    print(output_txt.numpy())\n",
    "    print(\"\\n\")\n",
    "    print(\"\".join(int_to_char[output_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size=10000\n",
    "batch=64\n",
    "dataset=dataset.shuffle(buffer_size).batch(batch_size=64,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding,GRU\n",
    "def build_model(output_dim,vocab_size,batch_size,units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,output_dim,batch_input_shape=(batch_size,None)))\n",
    "    \n",
    "    model.add(LSTM(\n",
    "      units=units,\n",
    "      return_sequences=True,\n",
    "      stateful=True,recurrent_initializer='glorot_uniform'\n",
    "      \n",
    "    ))\n",
    "                                 \n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile(loss=loss,optimizer=Adam(0.001),metrics=['sparse_categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=build_model(embed_size,vocab_size,batch,units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 56)            2128      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          4427776   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 38)            38950     \n",
      "=================================================================\n",
      "Total params: 4,468,854\n",
      "Trainable params: 4,468,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for input_example_batch,target_example_batch in dataset.take(1):\n",
    "      batch_example_predictions=model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 100])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
       "array([ 9,  0, 36, 16, 31,  1, 23, 26, 26, 22, 30,  1, 19, 16,  1, 23, 20,\n",
       "       22, 16,  1, 12,  1, 22, 20, 25, 18,  9,  1, 13, 16, 19, 26, 23, 15,\n",
       "        6,  1, 19, 20, 30,  1, 16, 36, 16,  6,  0, 12, 30,  1, 13, 29, 20,\n",
       "       18, 19, 31,  1, 12, 30,  1, 20, 30,  1, 31, 19, 16,  1, 16, 12, 18,\n",
       "       23, 16,  5, 30,  6,  1, 23, 20, 18, 19, 31, 16, 25, 30,  1, 17, 26,\n",
       "       29, 31, 19,  0, 14, 26, 25, 31, 29, 26, 23, 23, 20, 25, 18])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 100, 38])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_example_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
       "array([ 0, 36, 16, 31,  1, 23, 26, 26, 22, 30,  1, 19, 16,  1, 23, 20, 22,\n",
       "       16,  1, 12,  1, 22, 20, 25, 18,  9,  1, 13, 16, 19, 26, 23, 15,  6,\n",
       "        1, 19, 20, 30,  1, 16, 36, 16,  6,  0, 12, 30,  1, 13, 29, 20, 18,\n",
       "       19, 31,  1, 12, 30,  1, 20, 30,  1, 31, 19, 16,  1, 16, 12, 18, 23,\n",
       "       16,  5, 30,  6,  1, 23, 20, 18, 19, 31, 16, 25, 30,  1, 17, 26, 29,\n",
       "       31, 19,  0, 14, 26, 25, 31, 29, 26, 23, 23, 20, 25, 18,  1])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_example_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 38), dtype=float32, numpy=\n",
       "array([[ 0.00187001,  0.00031166, -0.00051023, ...,  0.00079601,\n",
       "         0.00208398, -0.00043685],\n",
       "       [ 0.00228901, -0.00033881, -0.00190261, ..., -0.00022432,\n",
       "         0.00131825, -0.000849  ],\n",
       "       [ 0.00532284,  0.00218869, -0.00362678, ...,  0.00170633,\n",
       "         0.00149027,  0.00127491],\n",
       "       ...,\n",
       "       [ 0.00147808, -0.00484045,  0.00143492, ..., -0.00526975,\n",
       "         0.00066018,  0.00122667],\n",
       "       [ 0.00181574, -0.00329164,  0.00406523, ..., -0.00401777,\n",
       "        -0.00036749, -0.0017116 ],\n",
       "       [ 0.00114387, -0.00479589,  0.00379273, ..., -0.00564774,\n",
       "        -0.00025505,  0.00045959]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape(batch_size,input_length,vocab_size)\n",
    "batch_example_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples=tf.random.categorical(batch_example_predictions[0],num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(tf.random.categorical(batch_example_predictions[0],num_samples=1)[-1,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1), dtype=int64, numpy=\n",
       "array([[30],\n",
       "       [24],\n",
       "       [32],\n",
       "       [37],\n",
       "       [16],\n",
       "       [ 1],\n",
       "       [17],\n",
       "       [22],\n",
       "       [ 5],\n",
       "       [26],\n",
       "       [ 9],\n",
       "       [32],\n",
       "       [24],\n",
       "       [32],\n",
       "       [ 3],\n",
       "       [28],\n",
       "       [ 9],\n",
       "       [30],\n",
       "       [27],\n",
       "       [31],\n",
       "       [ 0],\n",
       "       [ 2],\n",
       "       [26],\n",
       "       [32],\n",
       "       [35],\n",
       "       [18],\n",
       "       [32],\n",
       "       [18],\n",
       "       [34],\n",
       "       [ 1],\n",
       "       [33],\n",
       "       [32],\n",
       "       [20],\n",
       "       [14],\n",
       "       [ 9],\n",
       "       [32],\n",
       "       [32],\n",
       "       [ 2],\n",
       "       [ 1],\n",
       "       [ 2],\n",
       "       [17],\n",
       "       [15],\n",
       "       [36],\n",
       "       [25],\n",
       "       [ 2],\n",
       "       [34],\n",
       "       [ 0],\n",
       "       [15],\n",
       "       [ 8],\n",
       "       [34],\n",
       "       [ 0],\n",
       "       [ 3],\n",
       "       [28],\n",
       "       [35],\n",
       "       [28],\n",
       "       [30],\n",
       "       [33],\n",
       "       [11],\n",
       "       [13],\n",
       "       [ 4],\n",
       "       [15],\n",
       "       [ 7],\n",
       "       [10],\n",
       "       [31],\n",
       "       [ 5],\n",
       "       [ 7],\n",
       "       [34],\n",
       "       [ 7],\n",
       "       [ 1],\n",
       "       [28],\n",
       "       [ 0],\n",
       "       [20],\n",
       "       [10],\n",
       "       [33],\n",
       "       [28],\n",
       "       [26],\n",
       "       [35],\n",
       "       [27],\n",
       "       [24],\n",
       "       [19],\n",
       "       [34],\n",
       "       [ 9],\n",
       "       [25],\n",
       "       [32],\n",
       "       [11],\n",
       "       [11],\n",
       "       [ 6],\n",
       "       [16],\n",
       "       [22],\n",
       "       [20],\n",
       "       [ 9],\n",
       "       [ 4],\n",
       "       [24],\n",
       "       [14],\n",
       "       [18],\n",
       "       [23],\n",
       "       [23],\n",
       "       [29],\n",
       "       [ 5],\n",
       "       [12]], dtype=int64)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011438701"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_example_predictions[0][-1,0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples=tf.squeeze(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s', 'm', 'u', 'z', 'e', ' ', 'f', 'k', \"'\", 'o', ':', 'u', 'm',\n",
       "       'u', '$', 'q', ':', 's', 'p', 't', '\\n', '!', 'o', 'u', 'x', 'g',\n",
       "       'u', 'g', 'w', ' ', 'v', 'u', 'i', 'c', ':', 'u', 'u', '!', ' ',\n",
       "       '!', 'f', 'd', 'y', 'n', '!', 'w', '\\n', 'd', '.', 'w', '\\n', '$',\n",
       "       'q', 'x', 'q', 's', 'v', '?', 'b', '&', 'd', '-', ';', 't', \"'\",\n",
       "       '-', 'w', '-', ' ', 'q', '\\n', 'i', ';', 'v', 'q', 'o', 'x', 'p',\n",
       "       'm', 'h', 'w', ':', 'n', 'u', '?', '?', ',', 'e', 'k', 'i', ':',\n",
       "       '&', 'm', 'c', 'g', 'l', 'l', 'r', \"'\", 'a'], dtype='<U1')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_char[random_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([3.635406 , 3.636222 , 3.6379583, 3.6362448, 3.6365352, 3.636787 ,\n",
       "       3.6393318, 3.6380754, 3.6332123, 3.6379316, 3.640997 , 3.6362758,\n",
       "       3.6351805, 3.6436336, 3.6376798, 3.6375248, 3.6353955, 3.637597 ,\n",
       "       3.639986 , 3.6341379, 3.643597 , 3.6367545, 3.6370041, 3.6384733,\n",
       "       3.645325 , 3.6398633, 3.640744 , 3.6373827, 3.6389246, 3.63321  ,\n",
       "       3.6398818, 3.6369796, 3.632824 , 3.6402133, 3.6440184, 3.6347215,\n",
       "       3.6364026, 3.6315572, 3.6407158, 3.636084 , 3.6342268, 3.6356025,\n",
       "       3.6373181, 3.637705 , 3.6407495, 3.63679  , 3.6379685, 3.6357782,\n",
       "       3.6353822, 3.6369388, 3.6421204, 3.6343837, 3.6350257, 3.6438131,\n",
       "       3.6339073, 3.634898 , 3.6403804, 3.6379185, 3.6309266, 3.638724 ,\n",
       "       3.6337855, 3.6330333, 3.635371 , 3.6412673, 3.6362453, 3.63388  ,\n",
       "       3.644438 , 3.6354144, 3.6329114, 3.6375437, 3.6342328, 3.6384807,\n",
       "       3.6393607, 3.63931  , 3.6373072, 3.642086 , 3.6313818, 3.6346319,\n",
       "       3.631589 , 3.6412396, 3.6336458, 3.6360712, 3.640363 , 3.6369715,\n",
       "       3.6366913, 3.637389 , 3.635442 , 3.6368499, 3.6411614, 3.637765 ,\n",
       "       3.6359756, 3.6396456, 3.6393805, 3.636048 , 3.6337059, 3.635294 ,\n",
       "       3.637823 , 3.640967 , 3.642418 , 3.642255 ], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(target_example_batch,batch_example_predictions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "lstm_dir_checkpoints= './training_checkpoints_LSTM'\n",
    "#checkpoint_prefix = os.path.join(lstm_dir_checkpoints, \"checkpt_{epoch}\") #name\n",
    "#checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "172/172 [==============================] - 464s 3s/step - loss: 1.9622 - sparse_categorical_accuracy: 0.4191\n",
      "Epoch 2/40\n",
      "172/172 [==============================] - 473s 3s/step - loss: 1.6964 - sparse_categorical_accuracy: 0.4919\n",
      "Epoch 3/40\n",
      "172/172 [==============================] - 462s 3s/step - loss: 1.5451 - sparse_categorical_accuracy: 0.5337\n",
      "Epoch 4/40\n",
      "172/172 [==============================] - 467s 3s/step - loss: 1.4518 - sparse_categorical_accuracy: 0.5580\n",
      "Epoch 5/40\n",
      "172/172 [==============================] - 466s 3s/step - loss: 1.3864 - sparse_categorical_accuracy: 0.5754\n",
      "Epoch 6/40\n",
      "172/172 [==============================] - 468s 3s/step - loss: 1.3343 - sparse_categorical_accuracy: 0.5887\n",
      "Epoch 7/40\n",
      "172/172 [==============================] - 476s 3s/step - loss: 1.2899 - sparse_categorical_accuracy: 0.6004\n",
      "Epoch 8/40\n",
      "172/172 [==============================] - 470s 3s/step - loss: 1.2481 - sparse_categorical_accuracy: 0.6127\n",
      "Epoch 9/40\n",
      "172/172 [==============================] - 475s 3s/step - loss: 1.2065 - sparse_categorical_accuracy: 0.6246\n",
      "Epoch 10/40\n",
      "172/172 [==============================] - 474s 3s/step - loss: 1.1650 - sparse_categorical_accuracy: 0.6374\n",
      "Epoch 11/40\n",
      "172/172 [==============================] - 475s 3s/step - loss: 1.1235 - sparse_categorical_accuracy: 0.6509\n",
      "Epoch 12/40\n",
      "172/172 [==============================] - 475s 3s/step - loss: 1.0776 - sparse_categorical_accuracy: 0.6659\n",
      "Epoch 13/40\n",
      "172/172 [==============================] - 472s 3s/step - loss: 1.0340 - sparse_categorical_accuracy: 0.6812\n",
      "Epoch 14/40\n",
      "172/172 [==============================] - 473s 3s/step - loss: 0.9868 - sparse_categorical_accuracy: 0.6977\n",
      "Epoch 15/40\n",
      "172/172 [==============================] - 469s 3s/step - loss: 0.9424 - sparse_categorical_accuracy: 0.7133\n",
      "Epoch 16/40\n",
      "172/172 [==============================] - 473s 3s/step - loss: 0.8970 - sparse_categorical_accuracy: 0.7303\n",
      "Epoch 17/40\n",
      "172/172 [==============================] - 464s 3s/step - loss: 0.8557 - sparse_categorical_accuracy: 0.7463\n",
      "Epoch 18/40\n",
      "172/172 [==============================] - 464s 3s/step - loss: 0.8152 - sparse_categorical_accuracy: 0.7616\n",
      "Epoch 19/40\n",
      "172/172 [==============================] - 468s 3s/step - loss: 0.7769 - sparse_categorical_accuracy: 0.7757\n",
      "Epoch 20/40\n",
      "172/172 [==============================] - 461s 3s/step - loss: 0.7433 - sparse_categorical_accuracy: 0.7887\n",
      "Epoch 21/40\n",
      "172/172 [==============================] - 468s 3s/step - loss: 0.7119 - sparse_categorical_accuracy: 0.8007\n",
      "Epoch 22/40\n",
      "172/172 [==============================] - 472s 3s/step - loss: 0.6840 - sparse_categorical_accuracy: 0.8112\n",
      "Epoch 23/40\n",
      "172/172 [==============================] - 460s 3s/step - loss: 0.6587 - sparse_categorical_accuracy: 0.8211\n",
      "Epoch 24/40\n",
      "172/172 [==============================] - 466s 3s/step - loss: 0.6384 - sparse_categorical_accuracy: 0.8293\n",
      "Epoch 25/40\n",
      "172/172 [==============================] - 466s 3s/step - loss: 0.6157 - sparse_categorical_accuracy: 0.8373\n",
      "Epoch 26/40\n",
      "172/172 [==============================] - 461s 3s/step - loss: 0.5998 - sparse_categorical_accuracy: 0.8440\n",
      "Epoch 27/40\n",
      "172/172 [==============================] - 461s 3s/step - loss: 0.5844 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 28/40\n",
      "172/172 [==============================] - 474s 3s/step - loss: 0.5688 - sparse_categorical_accuracy: 0.8560\n",
      "Epoch 29/40\n",
      "172/172 [==============================] - 463s 3s/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8608\n",
      "Epoch 30/40\n",
      "172/172 [==============================] - 590s 3s/step - loss: 0.5428 - sparse_categorical_accuracy: 0.8650\n",
      "Epoch 31/40\n",
      "172/172 [==============================] - 733s 4s/step - loss: 0.5344 - sparse_categorical_accuracy: 0.8687\n",
      "Epoch 32/40\n",
      "172/172 [==============================] - 742s 4s/step - loss: 0.5230 - sparse_categorical_accuracy: 0.8730\n",
      "Epoch 33/40\n",
      "172/172 [==============================] - 734s 4s/step - loss: 0.5161 - sparse_categorical_accuracy: 0.8755\n",
      "Epoch 34/40\n",
      "172/172 [==============================] - 762s 4s/step - loss: 0.5080 - sparse_categorical_accuracy: 0.8784\n",
      "Epoch 35/40\n",
      "172/172 [==============================] - 475s 3s/step - loss: 0.4996 - sparse_categorical_accuracy: 0.8815\n",
      "Epoch 36/40\n",
      "172/172 [==============================] - 465s 3s/step - loss: 0.4943 - sparse_categorical_accuracy: 0.8835\n",
      "Epoch 37/40\n",
      "172/172 [==============================] - 473s 3s/step - loss: 0.4871 - sparse_categorical_accuracy: 0.8857\n",
      "Epoch 38/40\n",
      "172/172 [==============================] - 475s 3s/step - loss: 0.4802 - sparse_categorical_accuracy: 0.8887\n",
      "Epoch 39/40\n",
      "172/172 [==============================] - 476s 3s/step - loss: 0.4767 - sparse_categorical_accuracy: 0.8890\n",
      "Epoch 40/40\n",
      "172/172 [==============================] - 464s 3s/step - loss: 0.4742 - sparse_categorical_accuracy: 0.8901\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=40, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints_LSTM\\\\checkpt_40'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(lstm_dir_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.embeddings.Embedding object at 0x00000206A3B42388> and <tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x00000206A3B3C088>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x00000206A3B3C088> and <tensorflow.python.keras.layers.core.Dense object at 0x00000206FA30D9C8>).\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 56)             2128      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           4427776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 38)             38950     \n",
      "=================================================================\n",
      "Total params: 4,468,854\n",
      "Trainable params: 4,468,854\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = build_model(embed_size,vocab_size,1,units)\n",
    "lstm_model.load_weights(tf.train.latest_checkpoint(lstm_dir_checkpoints))\n",
    "lstm_model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "lstm_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 200 #Number of characters to be generated\n",
    "\n",
    "    input_eval = [char_to_int[s] for s in start_string] #vectorising input\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 0.1\n",
    "    \n",
    "    k=0\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    print(input_eval.shape)\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(int_to_char[predicted_id])\n",
    "        #start_string=start_string+int_to_char[predicted_id]\n",
    "        #input_eval = [char_to_int[s] for s in start_string[k+1:]] #vectorising input\n",
    "        #print(len(input_eval))\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "        #k+=1\n",
    "        \n",
    "\n",
    "    return (start_string+''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your starting string: first\n",
      "(1, 5)\n",
      "first keep the people, which\n",
      "are made the conducts of this place of constable,\n",
      "and fear'd as ourselves to see 'emeand he shall be frief:\n",
      "the more i bid thee dead, and i emplay\n",
      "the thumber is not hot i see \n"
     ]
    }
   ],
   "source": [
    "lstm_test = input(\"Enter your starting string: \")\n",
    "print(generate_text(lstm_model, start_string=lstm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
